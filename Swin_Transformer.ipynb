{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1VSYG-5zCAC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "base_dir = \"/content/tiny-imagenet-200\"\n",
        "val_dir = os.path.join(base_dir, \"val\")\n",
        "images_dir = os.path.join(val_dir, \"images\")\n",
        "ann_file = os.path.join(val_dir, \"val_annotations.txt\")\n",
        "\n",
        "# Read annotations\n",
        "with open(ann_file) as f:\n",
        "    annotations = [line.strip().split('\\t') for line in f]\n",
        "\n",
        "# Create class folders and move images\n",
        "for img, cls, *_ in annotations:\n",
        "    cls_dir = os.path.join(val_dir, cls)\n",
        "    os.makedirs(cls_dir, exist_ok=True)\n",
        "    shutil.move(\n",
        "        os.path.join(images_dir, img),\n",
        "        os.path.join(cls_dir, img)\n",
        "    )\n",
        "\n",
        "os.rmdir(images_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STybOEKGKrNt"
      },
      "outputs": [],
      "source": [
        "!pip install -q tf-models-official"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MR2VaR0HzqES"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as tfla\n",
        "import tensorflow.keras.models as tfm\n",
        "import tensorflow.keras.optimizers as tfo\n",
        "import tensorflow.keras.losses as tflo\n",
        "import matplotlib.pyplot as plt\n",
        "from official.vision.ops import augment\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBjPOtYPzsqi",
        "outputId": "8c779a9e-f999-4958-c3dd-599501ba2065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 100000 files belonging to 200 classes.\n",
            "Found 10000 files belonging to 200 classes.\n"
          ]
        }
      ],
      "source": [
        "with open(\"tiny-imagenet-200/wnids.txt\") as f:\n",
        "    wnids = [line.strip() for line in f]\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"tiny-imagenet-200/train\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=wnids,\n",
        "    image_size=(256, 256),\n",
        "    batch_size=None,\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"tiny-imagenet-200/val\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=wnids,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=128,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SBptpcbzwPa"
      },
      "outputs": [],
      "source": [
        "def crop_image(image, label):\n",
        "  # image shape: [h, w, c]\n",
        "  # label shape: [num_class,]\n",
        "  image = tf.image.random_crop(image, (224, 224, 3))\n",
        "  image = tf.image.random_flip_left_right(image)\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1KhtH7D0L6e"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(crop_image, num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiFN2iP71pl9"
      },
      "outputs": [],
      "source": [
        "def apply_randaugment(image, label):\n",
        "  # image shape: [h, w, c]\n",
        "  # label shape: [num_class,]\n",
        "  augmenter = augment.RandAugment(num_layers=2, magnitude=9)\n",
        "  return augmenter.distort(image), label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaQNZ5Hg2ELl"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(apply_randaugment, num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgMsLERY0VCH"
      },
      "outputs": [],
      "source": [
        "def normalise_image(image, label):\n",
        "  # image shape: [h, w, c]\n",
        "  # label shape: [num_class,]\n",
        "  mean = tf.constant([0.485, 0.456, 0.406])\n",
        "  std = tf.constant([0.229, 0.224, 0.225])\n",
        "\n",
        "  image = (image / 255.0 - mean) / std\n",
        "\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99xmoOde00PQ"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(normalise_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.map(normalise_image, num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1ep8mhW4Mdf"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.batch(128)\n",
        "combined_ds = train_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qJN8VAa2JyT"
      },
      "outputs": [],
      "source": [
        "def mixup(images, labels):\n",
        "  # images shape: [batchsize, h, w, c]\n",
        "  # labels shape: [batchsize, num_class]\n",
        "  batch_size = tf.shape(images)[0]\n",
        "\n",
        "  gamma_1 = tf.random.gamma(shape=[batch_size, 1], alpha=0.2)\n",
        "  gamma_2 = tf.random.gamma(shape=[batch_size, 1], alpha=0.2)\n",
        "  lam = gamma_1 / (gamma_1 + gamma_2)\n",
        "\n",
        "  indices = tf.random.shuffle(tf.range(batch_size))\n",
        "  shuffled_images = tf.gather(images, indices)\n",
        "  shuffled_labels = tf.gather(labels, indices)\n",
        "\n",
        "  images_lam = tf.reshape(lam, [-1, 1, 1, 1])\n",
        "  labels_lam = lam\n",
        "\n",
        "\n",
        "  images = images_lam * images + (1 - images_lam) * shuffled_images\n",
        "  labels = labels_lam * labels + (1 - labels_lam) * shuffled_labels\n",
        "\n",
        "  return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArnD3cNh56yo"
      },
      "outputs": [],
      "source": [
        "mixup_ds = train_ds.map(mixup, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "combined_ds = combined_ds.concatenate(mixup_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUosbU3q7tGh"
      },
      "outputs": [],
      "source": [
        "def cutmix(images, labels):\n",
        "  # images shape: [batchsize, h, w, c]\n",
        "  # labels shape: [batchsize, num_class]\n",
        "  batch_size = tf.shape(images)[0]\n",
        "  img_height = tf.shape(images)[1]\n",
        "  img_width = tf.shape(images)[2]\n",
        "\n",
        "  gamma_1 = tf.random.gamma(shape=[batch_size, 1], alpha=0.2)\n",
        "  gamma_2 = tf.random.gamma(shape=[batch_size, 1], alpha=0.2)\n",
        "  # lam is the cut percentage with shape: [batch_size, 1]\n",
        "  lam = gamma_1 / (gamma_1 + gamma_2)\n",
        "\n",
        "  # we find the cut image height and width all with shape [batch_size, 1]\n",
        "  cut_height = tf.cast(tf.cast(img_height, tf.float32) * tf.sqrt(lam), tf.int32)\n",
        "  cut_width = tf.cast(tf.cast(img_width, tf.float32) * tf.sqrt(lam), tf.int32)\n",
        "\n",
        "  min_height = tf.cast(cut_height // 2, tf.int32)\n",
        "  max_height = tf.cast(img_height - 1 - cut_height // 2, tf.int32)\n",
        "  cut_centre_x = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=1,\n",
        "                                   dtype=tf.float32)\n",
        "  cut_centre_x = cut_centre_x * tf.cast(max_height - min_height, tf.float32) + tf.cast(min_height, tf.float32)\n",
        "\n",
        "  min_width = tf.cast(cut_width // 2, tf.int32)\n",
        "  max_width = tf.cast(img_width - 1 - cut_width // 2, tf.int32)\n",
        "  cut_centre_y = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=1,\n",
        "                                   dtype=tf.float32)\n",
        "  cut_centre_y = cut_centre_y * tf.cast(max_width - min_width, tf.float32) + tf.cast(min_width, tf.float32)\n",
        "\n",
        "  # find four conors for rectangles all with shape: [batch_size, 1]\n",
        "  x1 = tf.cast(tf.cast(cut_centre_x, tf.int32) - cut_height // 2, tf.int32)\n",
        "  x2 = tf.cast(tf.cast(cut_centre_x, tf.int32) + cut_height // 2, tf.int32)\n",
        "  y1 = tf.cast(tf.cast(cut_centre_y, tf.int32) - cut_width // 2, tf.int32)\n",
        "  y2 = tf.cast(tf.cast(cut_centre_y, tf.int32) + cut_width // 2, tf.int32)\n",
        "\n",
        "  x_indices = tf.range(img_height)\n",
        "  y_indices = tf.range(img_width)\n",
        "  y_grid, x_grid = tf.meshgrid(y_indices, x_indices)\n",
        "  x_grid = tf.reshape(x_grid, [1, img_height, img_width])\n",
        "  y_grid = tf.reshape(y_grid, [1, img_height, img_width])\n",
        "\n",
        "  x1 = tf.reshape(x1, [batch_size, 1, 1])\n",
        "  x2 = tf.reshape(x2, [batch_size, 1, 1])\n",
        "  y1 = tf.reshape(y1, [batch_size, 1, 1])\n",
        "  y2 = tf.reshape(y2, [batch_size, 1, 1])\n",
        "\n",
        "  # mask matrix with shape : [batch_size, h, w]\n",
        "  mask = tf.logical_and(tf.logical_and(x1 <= x_grid, x_grid <= x2), tf.logical_and(\n",
        "      y1 <= y_grid, y_grid <= y2))\n",
        "  mask = tf.cast(mask, dtype=tf.int32)\n",
        "\n",
        "  indices = tf.random.shuffle(tf.range(batch_size))\n",
        "  shuffled_images = tf.gather(images, indices)\n",
        "  shuffled_labels = tf.gather(labels, indices)\n",
        "\n",
        "  mask = tf.reshape(mask, [batch_size, img_height, img_width, 1])\n",
        "\n",
        "  images = images * tf.cast(1 - mask, dtype=tf.float32) + shuffled_images * tf.cast(mask, dtype=tf.float32)\n",
        "  labels = labels * (1.0 - lam) + shuffled_labels * lam\n",
        "\n",
        "  return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWd5qh1-0GS-"
      },
      "outputs": [],
      "source": [
        "cutmix_ds = train_ds.map(cutmix, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "combined_ds = combined_ds.concatenate(cutmix_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnJgV3nbY0JU"
      },
      "outputs": [],
      "source": [
        "def erase(images, labels):\n",
        "  # images shape: [batch_size, h, w, c]\n",
        "  # labels shape: [batch_size, num_class]\n",
        "  batch_size = tf.shape(images)[0]\n",
        "  img_height = tf.shape(images)[1]\n",
        "  img_width = tf.shape(images)[2]\n",
        "\n",
        "  # lam is the cut percentage with shape: [batch_size, 1]\n",
        "  lam = tf.random.uniform(shape=(batch_size, 1), minval=0.2, maxval=0.5, dtype=tf.float32)\n",
        "\n",
        "  # we find the cut image height and width all with shape [batch_size, 1]\n",
        "  erase_height = tf.cast(tf.cast(img_height, tf.float32) * tf.sqrt(lam), tf.int32)\n",
        "  erase_width = tf.cast(tf.cast(img_width, tf.float32) * tf.sqrt(lam), tf.int32)\n",
        "\n",
        "  min_height = tf.cast(erase_height // 2, tf.int32)\n",
        "  max_height = tf.cast(img_height - 1 - erase_height // 2, tf.int32)\n",
        "  erase_centre_x = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=1,\n",
        "                                   dtype=tf.float32)\n",
        "  erase_centre_x = erase_centre_x * tf.cast(max_height - min_height, tf.float32) + tf.cast(min_height, tf.float32)\n",
        "\n",
        "  min_width = tf.cast(erase_width // 2, tf.int32)\n",
        "  max_width = tf.cast(img_width - 1 - erase_width // 2, tf.int32)\n",
        "  erase_centre_y = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=1,\n",
        "                                   dtype=tf.float32)\n",
        "  erase_centre_y = erase_centre_y * tf.cast(max_width - min_width, tf.float32) + tf.cast(min_width, tf.float32)\n",
        "\n",
        "  # find four conors for rectangles all with shape: [batch_size, 1]\n",
        "  x1 = tf.cast(tf.cast(erase_centre_x, tf.int32) - erase_height // 2, tf.int32)\n",
        "  x2 = tf.cast(tf.cast(erase_centre_x, tf.int32) + erase_height // 2, tf.int32)\n",
        "  y1 = tf.cast(tf.cast(erase_centre_y, tf.int32) - erase_width // 2, tf.int32)\n",
        "  y2 = tf.cast(tf.cast(erase_centre_y, tf.int32) + erase_width // 2, tf.int32)\n",
        "\n",
        "  x_indices = tf.range(img_height)\n",
        "  y_indices = tf.range(img_width)\n",
        "  y_grid, x_grid = tf.meshgrid(y_indices, x_indices)\n",
        "  x_grid = tf.reshape(x_grid, [1, img_height, img_width])\n",
        "  y_grid = tf.reshape(y_grid, [1, img_height, img_width])\n",
        "\n",
        "  x1 = tf.reshape(x1, [batch_size, 1, 1])\n",
        "  x2 = tf.reshape(x2, [batch_size, 1, 1])\n",
        "  y1 = tf.reshape(y1, [batch_size, 1, 1])\n",
        "  y2 = tf.reshape(y2, [batch_size, 1, 1])\n",
        "\n",
        "  # mask matrix with shape : [batch_size, h, w]\n",
        "  mask = tf.logical_and(tf.logical_and(x1 <= x_grid, x_grid <= x2), tf.logical_and(\n",
        "      y1 <= y_grid, y_grid <= y2))\n",
        "  mask = tf.cast(mask, dtype=tf.int32)\n",
        "\n",
        "  mask = tf.reshape(mask, [batch_size, img_height, img_width, 1])\n",
        "\n",
        "  images = images * tf.cast(1 - mask, dtype=tf.float32)\n",
        "\n",
        "  return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6KbHauB0q4e"
      },
      "outputs": [],
      "source": [
        "erase_ds = train_ds.map(erase, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "combined_ds = combined_ds.concatenate(erase_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQpUeGiIy08g"
      },
      "outputs": [],
      "source": [
        "def label_smoothing(labels, epsilon=0.1):\n",
        "  num_class = tf.cast(tf.shape(labels)[1], tf.float32)\n",
        "  return labels * (1.0 - epsilon) + epsilon / num_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDM3_ggA0txR"
      },
      "outputs": [],
      "source": [
        "combined_ds = combined_ds.map(lambda images, labels: (images, label_smoothing(labels)), num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5imjKapd-up"
      },
      "outputs": [],
      "source": [
        "combined_ds = combined_ds.shuffle(buffer_size=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xdyodzL6Bhm"
      },
      "outputs": [],
      "source": [
        "# TEST CODE\n",
        "def convert_back(image):\n",
        "  mean = tf.constant([0.485, 0.456, 0.406])\n",
        "  std = tf.constant([0.229, 0.224, 0.225])\n",
        "\n",
        "  image = (image * std + mean) * 255\n",
        "  image = tf.clip_by_value(image, 0, 255)\n",
        "  image = tf.cast(image, tf.int32)\n",
        "\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNOMOIDi69wU"
      },
      "outputs": [],
      "source": [
        "# TEST CODE\n",
        "def load_tinyimagenet_label_maps(tiny_imagenet_root):\n",
        "    # Load wnids (index -> wnid)\n",
        "    with open(f\"{tiny_imagenet_root}/wnids.txt\") as f:\n",
        "        wnids = [line.strip() for line in f]\n",
        "\n",
        "    # Load wnid -> words\n",
        "    wnid_to_words = {}\n",
        "    with open(f\"{tiny_imagenet_root}/words.txt\") as f:\n",
        "        for line in f:\n",
        "            wnid, words = line.strip().split(\"\\t\")\n",
        "            wnid_to_words[wnid] = words\n",
        "\n",
        "    return wnids, wnid_to_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKHKfsGh6-Nn"
      },
      "outputs": [],
      "source": [
        "# TEST CODE\n",
        "wnids, wnid_to_words = load_tinyimagenet_label_maps(\"tiny-imagenet-200\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiX1rU1D7CW7"
      },
      "outputs": [],
      "source": [
        "# TEST CODE\n",
        "def one_hot_to_tinyimagenet_word(one_hot_label, wnids, wnid_to_words):\n",
        "    \"\"\"\n",
        "    one_hot_label: tf.Tensor or np.array, shape (200,)\n",
        "    \"\"\"\n",
        "    # Convert one-hot to index\n",
        "    if isinstance(one_hot_label, tf.Tensor):\n",
        "        label_idx = int(tf.argmax(one_hot_label).numpy())\n",
        "    else:\n",
        "        label_idx = int(one_hot_label.argmax())\n",
        "\n",
        "    wnid = wnids[label_idx]\n",
        "    return wnid_to_words[wnid]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "QEFkTkMy7EYn",
        "outputId": "bfa72255-7ca1-4904-8ac4-4bc26c26555f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'%matplotlib inline\\n\\nfor images, labels in combined_ds.take(1):\\n  imagess, labelss = erase(images, labels)\\n  print(one_hot_to_tinyimagenet_word(labelss[0], wnids, wnid_to_words))\\n  plt.imshow(convert_back(imagess[0]).numpy())\\n  plt.axis(\"off\")\\n  plt.show()'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TEST CODE\n",
        "\"\"\"%matplotlib inline\n",
        "\n",
        "for images, labels in combined_ds.take(1):\n",
        "  imagess, labelss = erase(images, labels)\n",
        "  print(one_hot_to_tinyimagenet_word(labelss[0], wnids, wnid_to_words))\n",
        "  plt.imshow(convert_back(imagess[0]).numpy())\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEPrEr6_4t1T"
      },
      "outputs": [],
      "source": [
        "class patch_merging(tfla.Layer):\n",
        "  def __init__(self, dim):\n",
        "    # dim is the C in [B, N, C]\n",
        "    super().__init__()\n",
        "    self.dim = dim\n",
        "    self.norm = tfla.LayerNormalization()\n",
        "    self.proj = tfla.Dense(dim * 2, use_bias=False)\n",
        "\n",
        "  def call(self, x, h, w):\n",
        "    batch_size = tf.shape(x)[0]\n",
        "\n",
        "    x = tf.reshape(x, [batch_size, h, w, self.dim])\n",
        "\n",
        "    x0 = x[:, 0::2, 0::2, :]\n",
        "    x1 = x[:, 1::2, 0::2, :]\n",
        "    x2 = x[:, 0::2, 1::2, :]\n",
        "    x3 = x[:, 1::2, 1::2, :]\n",
        "\n",
        "    x = tf.concat([x0, x1, x2, x3], axis=-1)\n",
        "    x = tf.reshape(x, [batch_size, (h // 2) * (w // 2), 4 * self.dim])\n",
        "\n",
        "    x = self.norm(x)\n",
        "    x = self.proj(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhqumGmm9_WR"
      },
      "outputs": [],
      "source": [
        "def window_partition(x, window_size):\n",
        "  # x shape:[batch_size, h, w, c]\n",
        "  batch_size = tf.shape(x)[0]\n",
        "  h = tf.shape(x)[1]\n",
        "  w = tf.shape(x)[2]\n",
        "  c = tf.shape(x)[3]\n",
        "\n",
        "  # x shape:[batch_size, row_num, row in window, column_num, column in window, c]\n",
        "  x = tf.reshape(x, [batch_size, h // window_size, window_size, w // window_size,\n",
        "                     window_size, c])\n",
        "  # x shape:[batch_size, row_num, column_num, row in window, column in window, c]\n",
        "  x = tf.transpose(x, [0, 1, 3, 2, 4, 5])\n",
        "  # windows shape:[B_, window_size, window_size, c]\n",
        "  windows = tf.reshape(x, [-1, window_size, window_size, c])\n",
        "\n",
        "  return windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCCNcgolGdep"
      },
      "outputs": [],
      "source": [
        "def window_reverse(windows, window_size, h, w):\n",
        "  # windows shape:[batch_size * row_num * column_num, row in window, column in window, c]\n",
        "  batch_size = tf.shape(windows)[0] // (h // window_size) // (w // window_size)\n",
        "  c = tf.shape(windows)[3]\n",
        "  # windows shape:[batch_size, row_num, column_num, row in window, column in window, c]\n",
        "  windows = tf.reshape(windows, [batch_size, h // window_size, w // window_size,\n",
        "                                 window_size, window_size, c])\n",
        "  # windows shape:[batch_size, row_num, row in window, column_num, column in window, c]\n",
        "  windows = tf.transpose(windows, [0, 1, 3, 2, 4, 5])\n",
        "\n",
        "  windows = tf.reshape(windows, [batch_size, h, w, c])\n",
        "\n",
        "  return windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueE0PfW8Ituc"
      },
      "outputs": [],
      "source": [
        "class MLP(tfla.Layer):\n",
        "  def __init__(self, dim, mlp_ratio=4):\n",
        "    super().__init__()\n",
        "    self.dim = dim\n",
        "    self.mlp_ratio = mlp_ratio\n",
        "    self.fc1 = tfla.Dense(dim * mlp_ratio, use_bias=False, activation=\"gelu\")\n",
        "    self.fc2 = tfla.Dense(dim, use_bias=False)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NdHorMTLBuj"
      },
      "outputs": [],
      "source": [
        "class window_attention(tfla.Layer):\n",
        "  def __init__(self, dim, window_size, num_heads):\n",
        "    super().__init__()\n",
        "    self.dim = dim\n",
        "    self.num_heads = num_heads\n",
        "    self.window_size = window_size\n",
        "    self.head_dim = dim // num_heads\n",
        "    self.scale = tf.cast(self.head_dim, tf.float32) ** -0.5\n",
        "    self.qkv = tfla.Dense(dim * 3, use_bias=True)\n",
        "    self.dense = tfla.Dense(dim, use_bias=True)\n",
        "\n",
        "    self.num_rel_pos = (2 * window_size - 1) * (2 * window_size - 1)\n",
        "    self.rel_pos_emb = self.add_weight(\n",
        "        shape=(self.num_rel_pos, self.num_heads),\n",
        "        initializer=tf.random_normal_initializer(stddev=0.02),\n",
        "        trainable=True\n",
        "    )\n",
        "\n",
        "    self.coords_h = tf.range(self.window_size)\n",
        "    self.coords_w = tf.range(self.window_size)\n",
        "    # coords shape:[2, window_size, window_size]\n",
        "    self.coords = tf.stack(tf.meshgrid(self.coords_h, self.coords_w, indexing=\"ij\"))\n",
        "    # coords shape:[2, N]\n",
        "    self.coords = tf.reshape(self.coords, [2, -1])\n",
        "    # rel_pos shape:[2, N, N]\n",
        "    self.rel_pos = self.coords[:, :, None] - self.coords[:, None, :]\n",
        "    # rel_pos shape:[N, N, 2]\n",
        "    self.rel_pos = tf.transpose(self.rel_pos, [1, 2, 0])\n",
        "\n",
        "    self.col_pos = self.rel_pos[:,:,0] + self.window_size - 1\n",
        "    self.row_pos = self.rel_pos[:,:,1] + self.window_size - 1\n",
        "\n",
        "    self.rel_pos_index = self.col_pos * (2 * self.window_size - 1) + self.row_pos\n",
        "\n",
        "    # rel_pos_index shape:[N, N]\n",
        "    self.rel_pos_index = tf.cast(self.rel_pos_index, tf.int32)\n",
        "\n",
        "  def call(self, x, mask=None):\n",
        "    # x shape:[B_, N, c], where N is window_size * window_size\n",
        "    # B_ total number of windows inside a batch\n",
        "    # mask shape:[nW, N, N], where nW is the number of windows per image\n",
        "    B_ = tf.shape(x)[0]\n",
        "    N = self.window_size * self.window_size\n",
        "\n",
        "    # qkv shape:[B_, N, 3 * c]\n",
        "    qkv = self.qkv(x)\n",
        "    # qkv shape:[B_, N, 3, num_heads, head_dim]\n",
        "    qkv = tf.reshape(qkv, [B_, N, 3, self.num_heads, self.head_dim])\n",
        "    # qkv shape:[3, B_, num_heads, N, head_dim]\n",
        "    qkv = tf.transpose(qkv, [2, 0, 3, 1, 4])\n",
        "\n",
        "    # q, k, v shape:[B_, num_heads, N, head_dim]\n",
        "    q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "    q = q * self.scale\n",
        "    # attn shape:[B_, num_heads, N, N]\n",
        "    attn = tf.matmul(q, k, transpose_b=True)\n",
        "\n",
        "    rel_position_index = tf.reshape(self.rel_pos_index, [N*N])\n",
        "    # bias shape:[N*N, num_heads]\n",
        "    bias = tf.gather(self.rel_pos_emb, rel_position_index)\n",
        "    bias = tf.reshape(bias, [N, N, self.num_heads])\n",
        "    bias = tf.transpose(bias, [2, 0, 1])\n",
        "    bias = tf.reshape(bias, [1, self.num_heads, N, N])\n",
        "    attn = attn + bias\n",
        "\n",
        "    # apply mask\n",
        "    if(mask is not None):\n",
        "      num_windows_per_image = tf.shape(mask)[0]\n",
        "\n",
        "      attn = tf.reshape(attn, [-1, num_windows_per_image, self.num_heads, N, N])\n",
        "      mask = tf.reshape(mask, [1, num_windows_per_image, 1, N, N])\n",
        "      mask = tf.cast(mask, tf.float32)\n",
        "      attn = attn + mask\n",
        "      attn = tf.reshape(attn, [-1, self.num_heads, N, N])\n",
        "\n",
        "\n",
        "    attn = tf.nn.softmax(attn, axis=-1)\n",
        "    # out shape:[B_, num_heads, N, head_dim]\n",
        "    out = tf.matmul(attn, v)\n",
        "    # out shape:[B_, N, num_heads, head_dim]\n",
        "    out = tf.transpose(out, [0, 2, 1, 3])\n",
        "    out = tf.reshape(out, [B_, N, self.dim])\n",
        "\n",
        "    # out shape:[B_, N, C]\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pklm4Qej2Ec"
      },
      "outputs": [],
      "source": [
        "def create_mask(H, W, window_size, shifted_size):\n",
        "  # H: image height\n",
        "  # W: image weight\n",
        "  # window_size: window height and width\n",
        "  # shifted size: shift length\n",
        "\n",
        "  mask = np.zeros([H, W])\n",
        "\n",
        "  for i in range(0, H, window_size):\n",
        "    for j in range(0, W, window_size):\n",
        "      mask[i:i + window_size, j:j + window_size] = (i // window_size) * (W // window_size) + j // window_size\n",
        "\n",
        "  mask = np.roll(mask, -shifted_size, 0)\n",
        "  mask = np.roll(mask, -shifted_size, 1)\n",
        "\n",
        "  mask = np.reshape(mask, [1, H, W, 1])\n",
        "  mask = tf.convert_to_tensor(mask, dtype=tf.float32)\n",
        "  # mask shape: [num_windows_per_image, window_size, window_size, 1]\n",
        "  mask = window_partition(mask, window_size)\n",
        "  mask = tf.reshape(mask, [-1, window_size * window_size])\n",
        "\n",
        "  # mask_row shape: [num_windows_per_image, 1, N]\n",
        "  mask_row = tf.expand_dims(mask, axis=1)\n",
        "  # mask_col shape: [num_windows_per_image, N, 1]\n",
        "  mask_col = tf.expand_dims(mask, axis=2)\n",
        "\n",
        "  mask = tf.logical_not(tf.math.equal(mask_row, mask_col))\n",
        "  mask = mask * tf.cast(-1e9, tf.float32)\n",
        "\n",
        "  # mask shape:[num_windows_per_image, N, N]\n",
        "  return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kghiDJNEBoXl"
      },
      "outputs": [],
      "source": [
        "class swin_window_attention_forward(tfla.Layer):\n",
        "  def __init__(self, H, W, C, window_size, num_heads, shift_size):\n",
        "    super().__init__()\n",
        "    self.H = H\n",
        "    self.W = W\n",
        "    self.C = C\n",
        "    self.num_heads = num_heads\n",
        "    self.window_size = window_size\n",
        "    self.shift_size = shift_size\n",
        "    self.window_attention = window_attention(self.C, self.window_size, self.num_heads)\n",
        "\n",
        "  def call(self, x):\n",
        "    # x shape:[B, H, W, C]\n",
        "    if(x.shape.rank == 3):\n",
        "      x = tf.reshape(x, [-1, self.H, self.W, self.C])\n",
        "\n",
        "    if(self.shift_size > 0):\n",
        "      x = tf.roll(x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2])\n",
        "      mask_x = create_mask(H=self.H, W=self.W, window_size=self.window_size, shifted_size=self.shift_size)\n",
        "    else:\n",
        "      mask_x = None\n",
        "\n",
        "    # window_x shape:[B_, window_size, window_size, C]\n",
        "    window_x = window_partition(x, self.window_size)\n",
        "    # window_x shape:[B_, N, C]\n",
        "    window_x = tf.reshape(window_x, [-1, self.window_size * self.window_size, self.C])\n",
        "    # atte_x shape:[B_, N, C]\n",
        "    atte_x = self.window_attention(window_x, mask=mask_x)\n",
        "\n",
        "    # atte_x shape:[B_, window_size, window_size, C]\n",
        "    atte_x = tf.reshape(atte_x, [-1, self.window_size, self.window_size, self.C])\n",
        "\n",
        "    # x shape:[B, H, W, C]\n",
        "    x = window_reverse(atte_x, self.window_size, self.H, self.W)\n",
        "\n",
        "    if(self.shift_size > 0):\n",
        "      x = tf.roll(x, shift=[self.shift_size, self.shift_size], axis=[1, 2])\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XphxG2RJGtNo"
      },
      "outputs": [],
      "source": [
        "class swin_block(tfla.Layer):\n",
        "  def __init__(self, H, W, C, num_heads, window_size, shift_size):\n",
        "    super().__init__()\n",
        "    self.H = H\n",
        "    self.W = W\n",
        "    self.C = C\n",
        "    self.num_heads = num_heads\n",
        "    self.window_size = window_size\n",
        "    self.shift_size = shift_size\n",
        "\n",
        "    self.norm1 = tfla.LayerNormalization()\n",
        "    self.norm2 = tfla.LayerNormalization()\n",
        "    self.attn = swin_window_attention_forward(H, W, C, window_size, num_heads,shift_size)\n",
        "    self.MLP = MLP(C)\n",
        "\n",
        "  def call(self, x):\n",
        "    shortcut = x\n",
        "    x = self.norm1(x)\n",
        "    x = self.attn(x)\n",
        "    if(shortcut.shape.rank == 3):\n",
        "      shortcut = tf.reshape(shortcut, [-1, self.H, self.W, self.C])\n",
        "    x = x + shortcut\n",
        "\n",
        "    shortcut = x\n",
        "    x = self.norm2(x)\n",
        "    x = self.MLP(x)\n",
        "    x = x + shortcut\n",
        "\n",
        "    # x shape:[B, N, C]\n",
        "    return(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoKHVa8R0Oqw",
        "outputId": "5ddda804-f13e-4d23-a893-bd7b3a616b01"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'window_attention', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'window_attention_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'window_attention_2', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'window_attention_3', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'window_attention_4', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'window_attention_5', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'window_attention_6', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'window_attention_7', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'window_attention_8', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'window_attention_9', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'window_attention_10', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'window_attention_11', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "inputs = tfla.Input(shape=(224, 224, 3))\n",
        "\n",
        "# x shape:[B, H, W, C]\n",
        "x = tfla.Conv2D(\n",
        "    96,\n",
        "    4,\n",
        "    strides=4,\n",
        "    padding=\"valid\"\n",
        ")(inputs)\n",
        "x = tfla.LayerNormalization()(x)\n",
        "\n",
        "H = W = 56\n",
        "C = 96\n",
        "num_heads = [3, 6, 12, 24]\n",
        "depths = [2, 2, 6, 2]\n",
        "window_size = 7\n",
        "shift_size = window_size // 2\n",
        "for i in range(depths[0]):\n",
        "  if(i % 2 == 0):\n",
        "    x = swin_block(H, W, C, num_heads[0], window_size, 0)(x)\n",
        "  else:\n",
        "    x = swin_block(H, W, C, num_heads[0], window_size, shift_size)(x)\n",
        "x = patch_merging(C)(x, h=H, w=W)\n",
        "\n",
        "H = W = H // 2\n",
        "C = C * 2\n",
        "for i in range(depths[1]):\n",
        "  if(i % 2 == 0):\n",
        "    x = swin_block(H, W, C, num_heads[1], window_size, 0)(x)\n",
        "  else:\n",
        "    x = swin_block(H, W, C, num_heads[1], window_size, shift_size)(x)\n",
        "x = patch_merging(C)(x, h=H, w=W)\n",
        "\n",
        "H = W = H // 2\n",
        "C = C * 2\n",
        "for i in range(depths[2]):\n",
        "  if(i % 2 == 0):\n",
        "    x = swin_block(H, W, C, num_heads[2], window_size, 0)(x)\n",
        "  else:\n",
        "    x = swin_block(H, W, C, num_heads[2], window_size, shift_size)(x)\n",
        "x = patch_merging(C)(x, h=H, w=W)\n",
        "\n",
        "H = W = H // 2\n",
        "C = C * 2\n",
        "for i in range(depths[3]):\n",
        "    x = swin_block(H, W, C, num_heads[3], window_size, 0)(x)\n",
        "\n",
        "x = tfla.LayerNormalization()(x)\n",
        "x = tfla.GlobalAveragePooling2D()(x)\n",
        "outputs = tfla.Dense(200, activation=\"softmax\")(x)\n",
        "\n",
        "model = tfm.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 875
        },
        "id": "AqvnZYbMNSpu",
        "outputId": "80b2241c-f589-4680-f76d-87b213b465e4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_block (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">swin_block</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,555</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_block_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">swin_block</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,555</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ patch_merging (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">patch_merging</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_block_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">swin_block</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">407,862</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_block_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">swin_block</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">407,862</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ patch_merging_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">patch_merging</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">296,448</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_block_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">swin_block</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,626,732</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_block_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">swin_block</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,626,732</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_block_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">swin_block</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,626,732</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_block_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">swin_block</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,626,732</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_block_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">swin_block</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,626,732</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_block_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">swin_block</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,626,732</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ patch_merging_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">patch_merging</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,182,720</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_block_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">swin_block</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,497,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_block_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">swin_block</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,497,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_28          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">153,800</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │         \u001b[38;5;34m4,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │           \u001b[38;5;34m192\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_block (\u001b[38;5;33mswin_block\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │       \u001b[38;5;34m102,555\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_block_1 (\u001b[38;5;33mswin_block\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │       \u001b[38;5;34m102,555\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ patch_merging (\u001b[38;5;33mpatch_merging\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │        \u001b[38;5;34m74,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_block_2 (\u001b[38;5;33mswin_block\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m192\u001b[0m)    │       \u001b[38;5;34m407,862\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_block_3 (\u001b[38;5;33mswin_block\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m192\u001b[0m)    │       \u001b[38;5;34m407,862\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ patch_merging_1 (\u001b[38;5;33mpatch_merging\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │       \u001b[38;5;34m296,448\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_block_4 (\u001b[38;5;33mswin_block\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │     \u001b[38;5;34m1,626,732\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_block_5 (\u001b[38;5;33mswin_block\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │     \u001b[38;5;34m1,626,732\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_block_6 (\u001b[38;5;33mswin_block\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │     \u001b[38;5;34m1,626,732\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_block_7 (\u001b[38;5;33mswin_block\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │     \u001b[38;5;34m1,626,732\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_block_8 (\u001b[38;5;33mswin_block\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │     \u001b[38;5;34m1,626,732\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_block_9 (\u001b[38;5;33mswin_block\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │     \u001b[38;5;34m1,626,732\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ patch_merging_2 (\u001b[38;5;33mpatch_merging\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m768\u001b[0m)        │     \u001b[38;5;34m1,182,720\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_block_10 (\u001b[38;5;33mswin_block\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m6,497,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ swin_block_11 (\u001b[38;5;33mswin_block\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m6,497,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ layer_normalization_28          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │         \u001b[38;5;34m1,536\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_51 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │       \u001b[38;5;34m153,800\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,490,114</span> (97.24 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,490,114\u001b[0m (97.24 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,490,114</span> (97.24 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,490,114\u001b[0m (97.24 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0aL1THTNZLB"
      },
      "outputs": [],
      "source": [
        "steps_per_epoch = 3128\n",
        "epochs = 40\n",
        "total_steps = steps_per_epoch * epochs\n",
        "\n",
        "lr = tf.keras.optimizers.schedules.CosineDecay(\n",
        "    initial_learning_rate=5e-4,\n",
        "    decay_steps=total_steps\n",
        ")\n",
        "\n",
        "opt = tf.keras.optimizers.AdamW(learning_rate=lr, weight_decay=5e-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvV9Se6CYJtI",
        "outputId": "0a4d5e9c-ea44-4046-9c41-faaf18f046cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1152s\u001b[0m 335ms/step - accuracy: 0.0124 - loss: 5.2870\n",
            "Epoch 2/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1011s\u001b[0m 318ms/step - accuracy: 0.0167 - loss: 5.1936\n",
            "Epoch 3/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1012s\u001b[0m 319ms/step - accuracy: 0.0347 - loss: 5.0189\n",
            "Epoch 4/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1011s\u001b[0m 319ms/step - accuracy: 0.0602 - loss: 4.8289\n",
            "Epoch 5/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1012s\u001b[0m 319ms/step - accuracy: 0.0943 - loss: 4.6114\n",
            "Epoch 6/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1012s\u001b[0m 319ms/step - accuracy: 0.1210 - loss: 4.4479\n",
            "Epoch 7/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1012s\u001b[0m 319ms/step - accuracy: 0.1495 - loss: 4.2917\n",
            "Epoch 8/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1012s\u001b[0m 319ms/step - accuracy: 0.1775 - loss: 4.1399\n",
            "Epoch 9/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1012s\u001b[0m 319ms/step - accuracy: 0.2048 - loss: 4.0022\n",
            "Epoch 10/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1012s\u001b[0m 319ms/step - accuracy: 0.2305 - loss: 3.8813\n",
            "Epoch 11/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1013s\u001b[0m 319ms/step - accuracy: 0.2556 - loss: 3.7687\n",
            "Epoch 12/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1012s\u001b[0m 319ms/step - accuracy: 0.2790 - loss: 3.6601\n",
            "Epoch 13/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1012s\u001b[0m 319ms/step - accuracy: 0.3074 - loss: 3.5423\n",
            "Epoch 14/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1013s\u001b[0m 319ms/step - accuracy: 0.3311 - loss: 3.4335\n",
            "Epoch 15/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1012s\u001b[0m 319ms/step - accuracy: 0.3595 - loss: 3.3136\n",
            "Epoch 16/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1012s\u001b[0m 319ms/step - accuracy: 0.3901 - loss: 3.1935\n",
            "Epoch 17/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1012s\u001b[0m 319ms/step - accuracy: 0.4179 - loss: 3.0784\n",
            "Epoch 18/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1013s\u001b[0m 319ms/step - accuracy: 0.4472 - loss: 2.9687\n",
            "Epoch 19/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1012s\u001b[0m 319ms/step - accuracy: 0.4754 - loss: 2.8641\n",
            "Epoch 20/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1013s\u001b[0m 319ms/step - accuracy: 0.5043 - loss: 2.7572\n",
            "Epoch 21/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1012s\u001b[0m 319ms/step - accuracy: 0.5321 - loss: 2.6588\n",
            "Epoch 22/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1013s\u001b[0m 319ms/step - accuracy: 0.5630 - loss: 2.5570\n",
            "Epoch 23/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1013s\u001b[0m 319ms/step - accuracy: 0.5913 - loss: 2.4632\n",
            "Epoch 24/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1012s\u001b[0m 319ms/step - accuracy: 0.6190 - loss: 2.3711\n",
            "Epoch 25/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1013s\u001b[0m 319ms/step - accuracy: 0.6458 - loss: 2.2913\n",
            "Epoch 26/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1013s\u001b[0m 319ms/step - accuracy: 0.6721 - loss: 2.2101\n",
            "Epoch 27/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1013s\u001b[0m 319ms/step - accuracy: 0.6973 - loss: 2.1337\n",
            "Epoch 28/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1013s\u001b[0m 319ms/step - accuracy: 0.7198 - loss: 2.0681\n",
            "Epoch 29/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1013s\u001b[0m 319ms/step - accuracy: 0.7402 - loss: 2.0090\n",
            "Epoch 30/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1013s\u001b[0m 319ms/step - accuracy: 0.7574 - loss: 1.9577\n",
            "Epoch 31/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1013s\u001b[0m 319ms/step - accuracy: 0.7722 - loss: 1.9153\n",
            "Epoch 32/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1013s\u001b[0m 319ms/step - accuracy: 0.7858 - loss: 1.8752\n",
            "Epoch 33/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1013s\u001b[0m 319ms/step - accuracy: 0.7972 - loss: 1.8440\n",
            "Epoch 34/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1013s\u001b[0m 319ms/step - accuracy: 0.8054 - loss: 1.8171\n",
            "Epoch 35/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1013s\u001b[0m 319ms/step - accuracy: 0.8132 - loss: 1.7963\n",
            "Epoch 36/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1013s\u001b[0m 319ms/step - accuracy: 0.8196 - loss: 1.7766\n",
            "Epoch 37/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1014s\u001b[0m 319ms/step - accuracy: 0.8245 - loss: 1.7638\n",
            "Epoch 38/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1013s\u001b[0m 319ms/step - accuracy: 0.8267 - loss: 1.7555\n",
            "Epoch 39/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1013s\u001b[0m 319ms/step - accuracy: 0.8287 - loss: 1.7498\n",
            "Epoch 40/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1013s\u001b[0m 319ms/step - accuracy: 0.8288 - loss: 1.7493\n"
          ]
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    combined_ds,\n",
        "    epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WMf6vyj1dKkP"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HZC8roaRbRa8"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='lower right')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}